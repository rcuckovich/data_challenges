{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "0938028c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting Cuckovich_2_CAC.py\n"
     ]
    }
   ],
   "source": [
    "#%%file Cuckovich_2_CAC.py\n",
    "#  This is how I get pytest to pick up the file during testing\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Global variables to be updated between runs\n",
    "curr_mu_purch = .5\n",
    "curr_mu_max_purch = .8\n",
    "curr_phi_prod = .05\n",
    "\n",
    "# Import the data\n",
    "df_cac = pd.read_json(r'C:\\Users\\rcuck\\YvesBlue\\cac_data.json')\n",
    "\n",
    "# Look at the data\n",
    "print(df_cac)\n",
    "print(df_cac.head())\n",
    "print(df_cac.info())\n",
    "print(df_cac.describe())\n",
    "print(df_cac.columns)\n",
    "\n",
    "\n",
    "def strawman_org_emissions(df, mu_purch=.5, mu_max_purch=.8, phi_prod=.05):\n",
    "    # Do data cleaning\n",
    "\n",
    "    # Not sure if we want to clean everything with future data in mind or target only existing data\n",
    "    # I have selected cleaning everything but am leaving this here commented out as an option\n",
    "    # df.replace('Inconclusive', np.nan, inplace=True) \n",
    "    # df['Renewable Energy Purchased'] = pd.to_numeric(df['Renewable Energy Purchased'], errors='coerce')\n",
    "\n",
    "    # Change objects to float -- am including CO2 Analytic even though not in formula\n",
    "    # I would double check that the person asking for the data wants the output to be np.nan for rows that can't be computed\n",
    "    cols_to_clean = df.columns.drop('ISIN') \n",
    "    df[cols_to_clean] = df[cols_to_clean].apply(pd.to_numeric, errors='coerce')\n",
    "    \n",
    "    # The above is the more elegant way to clean all columns\n",
    "    #df['Total Energy Use'] = pd.to_numeric(df['Total Energy Use'], errors='coerce')\n",
    "    #df['Total CO2 Equivalents Emissions'] = pd.to_numeric(df['Total CO2 Equivalents Emissions'], errors='coerce')\n",
    "    #df['Renewable Energy Purchased'] = pd.to_numeric(df['Renewable Energy Purchased'], errors='coerce')\n",
    "    #df['Renewable Energy Produced'] = pd.to_numeric(df['Renewable Energy Produced'], errors='coerce')\n",
    "    #df['Carbon Credit Value'] = pd.to_numeric(df['Carbon Credit Value'], errors='coerce')\n",
    "    #df['CO2 Analytic'] = pd.to_numeric(df['CO2 Analytic'], errors='coerce')\n",
    "        \n",
    "    # mask to identify any rows with non-numeric values or zero in a denominator\n",
    "    mask1 = df['Total Energy Use'] > 0  # Notice zero not included because denominator value\n",
    "    mask2 = df['Total CO2 Equivalents Emissions'] >= 0\n",
    "    mask3 = df['Renewable Energy Purchased'] >= 0\n",
    "    mask4 = df['Renewable Energy Produced'] >= 0\n",
    "    mask5 = df['Carbon Credit Value'] >= 0\n",
    "    mask = mask1 & mask2 & mask3 & mask4 & mask5\n",
    "\n",
    "    \n",
    "    df.loc[mask, 'C02 Adjusted Total'] = (df['Total CO2 Equivalents Emissions'] - df['Carbon Credit Value']) * (1 - np.minimum((mu_purch * df['Renewable Energy Purchased'] / df['Total Energy Use']), mu_max_purch)) - (phi_prod * df['Renewable Energy Produced'])\n",
    "    \n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "834ec2f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "output = strawman_org_emissions(df_cac, curr_mu_purch, curr_mu_max_purch, curr_phi_prod)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "11b5ad3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "output.to_json(r'Cuckovich_2_CAC_output.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "f18bda82",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Suggest how to orchestrate updating the data and then computing this. Assume the data is saved in a PostgreSQL database.\n",
    "\n",
    "# I am still learning about this but I believe as in the first exercise, you could use Dagster to run any updates to the db then hand off to this python file to run on the updated data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32f9f7ac",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebc03b4e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
